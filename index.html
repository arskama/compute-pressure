
<!DOCTYPE html>
<meta charset="utf-8" />
<title>Compute Pressure API</title>
<script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove" defer></script>
<script class="remove">
  // All config options at https://respec.org/docs/
  const respecConfig = {
    shortName: "compute-pressure",
    group: "wicg",
    specStatus: "CG-DRAFT",
    xref: "web-platform",
    formerEditors: [
      {
        name: "Olivier Yiptong",
        company: "Google Inc.",
        companyURL: "https://google.com",
      }
    ],
    editors: [
      {
        name: "Victor Costan",
        company: "Google Inc.",
        companyURL: "https://google.com",
      },
      {
        name: "Kenneth Rohde Christiansen",
        company: "Intel Corporation",
        companyURL: "https://intel.com",
        w3cid: 57705,
      },
      {
        name: "Arnaud Mandy",
        company: "Intel Corporation",
        companyURL: "https://intel.com",
      }
    ],
    testSuiteURI: "https://github.com/web-platform-tests/wpt/labels/compute-pressure",
  };
</script>
<section id="abstract">
  <p>
    The <cite>Compute Pressure API</cite> provides a way for websites to react to changes
    in the CPU consumption of the target device, such that websites can trade off CPU
    resources for an improved user experience.
  </p>
</section>
<section id="sotd"></section>
<section class="informative">
  <h2>Introduction</h2>
  <p>
    Modern applications often need to balance the trade offs and advantages of fully utilizing
    the system's processing resources, in order to provide a modern and delightful user experience.
  </p>
  <p>
    As an example, many applications can render video effects with varying degrees of sophistication.
    These applications aim to provide the best user experience, while avoiding driving the user's
    device into a high [=load=] regime.
  </p>
  <p>
    [=Utilization=] of [=processing units=] close to and often reaching 100% can lead to a bad
    user experience, as different tasks are fighting for the processing time.
    This can lead to slowless, which is especially noticeable with input delay.

    Further, a prolonged utilization close 100% can cause the [=processing units=] to heat up due to prolonged
    [=boosting=], which can lead to [=throttling=], resulting in an even worse user experience.
  </p>
  <p>
    As a result of themal limits, many smartphones, tablets and laptops can become uncomfortably hot
    to the touch. The fans in laptops and desktops can become so loud that they disrupt conversations
    or the users’ ability to focus.
  </p>
  <p>
    In many cases, a device under high [=load=] appears to be unresponsive, as the operating
    system may fail to schedule the threads advancing the task that the user is waiting for. See also
    <a href="https://github.com/oyiptong/compute-pressure/#goals--motivating-use-cases">Compute Pressure:
    Use Cases</a>.
  </p>
</section>
<section>
  <h2>Concepts</h2>
  <p>
    This specification defines the following concepts:
  </p>
  <section>
    <h3><dfn>Processing Units</dfn></h3>
    <p>
      Computing devices consist of a multitude of different processing units such as the Central
      Processing Unit (<dfn>CPU</dfn>), Graphics Processing Unit (<dfn>GPU</dfn>) and many specialized
      processing units are becoming popular such as ones designed to accelerate specific tasks like
      machine learning or computer vision. This specification uses the term <dfn>XPU</dfn> to refer to
      <em>any</em> of these processing units.
    </p>
  </section>
  <section>
    <h3><dfn>Utilization</dfn></h3>
    <p>
      [=Processing Unit=] utilization refers to a device’s usage of the [=XPU=] processing
      resources, or the amount of work handled by an [=XPU=]. Not every task requires heavy [=XPU=]
      time as the task might depend on other resources, such as reading data from memory.
    </p>
    <p>
      [=XPU=] often contain multiple execution units/cores, so utilization refers to the
      <em>average percentage of the total working time of all execution units.</em>
    </p>
    <p>
      As an example, for a [=CPU=], the utilization is the fraction of time that each core has been
      executing code belonging to a thread, as opposed to being in an idle state.
    </p>
    <p>
      [=Processing Units=] are designed to run safely at 100% utilization. However, it means they have reached
      their limit and cannot take on additional work and maybe not even handle the current work at
      hand, resulting in perceptible slowness.
    </p>
  </section>
  <section>
    <h3><dfn>Load</dfn></h3>
    <p>
      For [=CPUs=], it is common to consider load in addition to [=utilization=]. Load is the number
      of processes (queue length) being executed or waiting to be by the CPU. When a system is
      heavily loaded, its [=CPU=] [=utilization=] is likely close to 100%, though a system with
      2 processes in the queue and one with 10 are not comparable. For this reason it is common
      to look at load average (average system load over a period of time) as a set of three
      numbers, which represent the load during the last one-, five-, and fifteen-minute periods.
    </p>
  </section>
  <section>
    <h3><dfn>Frequency</dfn></h3>
    <p>
      [=Processing units=] run at a certain frequency, also known as clock rate, expressed in
      cycles per second (e.g. gigahertz). The base frequency is a measure that the CPU manufacturer
      guarantees the [=processing unit=] can run at with reasonable cooling.
    </p>
    <p>
      To avoid [=processing units=] running at 100% utilization for long, some [=processing units=] can use <dfn>dynamic
      frequency scaling</dfn> to temporarily <dfn data-lt="boost|boosting">boost</dfn> the
      frequency of a certain execution unit and then assign the largest task to it, alleviating
      the poor user experience in many situations.
    </p>
    <p>
      The [=processing unit=] will try to increase the operating frequency in regular increments (steps)
      as required to meet demand. The increased frequency is limited by the [=processing unit=]'s power,
      current, and thermal limits, the number of execution units currently in use, and the maximum
      frequency of the active ones.
    </p>
    <p>
      [=Dynamic Frequency Scaling=] can also be used to
      <dfn data-lt="throttle|throttling">throttle</dfn> the execution,
      by slowing down the frequency to use less energy and conserve battery, especially in laptops.
    </p>
    <p>
      Throttling can also happen as a result of an [=processing unit=] reaching its thermal limits. This
      thermal throttling helps cool the [=processing unit=] down when it gets too hot by lowering the frequency.
    </p>
  </section>
</section>

<section> <h2>Compute Pressure Observer</h2>
The Compute Pressure Observer API enables developers to understand the utilization characteristics of a CPU.

<section data-dfn-for="ComputePressureObserverCallback">
  <h3>The <a>ComputePressureUpdateCallback</a> callback</h3>
  <pre class="idl">
    callback ComputePressureUpdateCallback = undefined (
      ComputePressureObserverUpdate update,
      ComputePressureObserver observer
    );
  </pre>
  This callback will be invoked when [=CPU=] [=frequency=] and/or [=utilization=] crosses the user
  set thresholds.
</section>

<section  data-dfn-for="ComputePressureObserver"> <h2>The <a>ComputePressureObserver</a> object</h2>
  <p>
    The {{ComputePressureObserver}} can be used to observe changes in the [=CPU=] [=frequency=] and
      <a>utilization</a>, following user set thresholds.
  </p>
  <p>
    Providing a list of thresholds effectively separates the resource usage into buckets. For example,
    the thresholds list `[0.5, 0.75, 0.9]` defines a 4-bucket scheme, where the buckets cover the ranges
    `[0-0.5[`, `[0.5-0.75[`, `[0.75-0.9[`, and `[0.9-1.0]`.
  </p>
  <aside class="note">
    <p>
      The user of the API can request an arbitary number of thresholds, but the User Agent may choose to
      observe only a subset of those requested.
    </p>
    <p>
      It is recommended that user agents allow at most 5 buckets (4 thresholds) for CPU utilization, and
      2 buckets (1 threshold) for CPU speed.
    </p>
  </aside>
  <pre class="idl">
    [Exposed=Window]
    interface ComputePressureObserver {
      constructor(
        ComputePressureUpdateCallback callback,
        optional ComputePressureObserverOptions options = {}
      );
      undefined observe();
      undefined unobserve();
    };
  </pre>

  <p>The <dfn>ComputePressureObserver</dfn> interface represents a {{ComputePressureObserver}}.</p>

  <section  data-dfn-for="ComputePressureObserver">
    <h3>
      Internal slots
    </h3>
    <p>
      A constructed  {{ComputePressureObserver}} object has the following internal slots.
    </p>
    <table class="simple">
      <thead>
        <tr>
          <th>
            Internal slot
          </th>
          <th>
            Initial value
          </th>
          <th>
            Description
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>
            <dfn>[[\Callback]]</dfn>
          </td>
          <td>
            {{undefined}}
          </td>
          <td>
            An optional function of type {{ComputePressureUpdateCallback}}.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>[[\CPUUtilizationThresholds]]</dfn>
          </td>
          <td>
            An empty [=list=].
          </td>
          <td>
            A [=list=] of {{double}}s between 0 and 1, representing
            the user requested {{CPU}} {{utilization}} thresholds.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>[[\CPUSpeedThresholds]]</dfn>
          </td>
          <td>
            An empty [=list=].
          </td>
          <td>
            A [=list=] of {{double}}s between 0 and 1, representing
            the user requested [=CPU=] [=frequency=] thresholds.
          </td>
        </tr>
      </tbody>
    </table>
  </section>
  <section>
    <h3>The <dfn>constructor()</dfn> method</h3>
    <p>
      The {{ComputePressureObserver/constructor()}} method, when invoked, MUST run the
      following step, given the arguments |callback:ComputePressureUpdateCallback| and
      |options:ComputePressureObserverOptions|:
      <ol class="algorithm">
        <li>
          Let |this:ComputePressureObserver| be a new the {{ComputePressureObserver}} object.
        </li>
        <li>
          Set |this|.{{ComputePressureObserver/[[Callback]]}} to |callback|.
        </li>
        <li>
          If |options|.|cpuUtilizationThresholds:list| exists, set |this|.{{ComputePressureObserver/[[CPUUtilizationThresholds]]}}
          be a [=list=] equal to that.
          If |options|.|cpuUtilizationThresholds:list| is greater in size than
          |this|.{{ComputePressureObserver/[[CPUUtilizationThresholds]]}} maximum allowed size, the extra elements of |options|.|cpuUtilizationThresholds:list|
          will be discarded.
        </li>
        <li>
          If any value in |this|.{{ComputePressureObserver/[[CPUUtilizationThresholds]]}} is less than 0.0 or greater than 1.0,
          throw a {{RangeError}} exception.
        </li>
        <li>
          Sort |this|.{{ComputePressureObserver/[[CPUUtilizationThresholds]]}} in ascending order.
        </li>
        <li>
          If |options|.|cpuSpeedThresholds:list| exists, set |this|.{{ComputePressureObserver/[[CPUSpeedThresholds]]}}
          be a [=list=] equal to that.
          If |options|.|cpuSpeedThresholds:list| is greater in size than
          |this|.{{ComputePressureObserver/[[CPUSpeedThresholds]]}} maximum allowed size, the extra elements of |options|.|cpuSpeedThresholds:list|
          will be discarded.
        </li>
        <li>
          If any value in |this|.{{ComputePressureObserver/[[CPUSpeedThresholds]]}} is less than 0.0 or greater than 1.0,
          throw a {{RangeError}} exception.
        </li>
        <li>
          Sort |this|.{{ComputePressureObserver/[[CPUSpeedThresholds]]}} in ascending order.
        </li>
        <li>
          Return |this|.
        </li>
    </p>
  </section>
  <section>
    <h3>The <dfn>observe()</dfn> method</h3>
    <p>
      The {{ComputePressureObserver/observe()}} method, when invoked, MUST run the
      following step:
      <ol class="algorithm">
        <li>
          Add {{ComputePressureObserver}} to the active observer [=list=]
        </li>
        <li>
          If |this:ComputePressureObserver| object is the first observer, sampling starts. Otherwise, it is already started.
          Sampling rate at which updates occur via |this|.{{ComputePressureObserver/[[Callback]]}} is <a href=https://infra.spec.whatwg.org/#implementation-defined> implementation-defined</a>.
        </li>
        <li>
          Update |this|.{{ComputePressureObserver/ComputePressureObserverUpdate/cpuSpeed}} with latest cpuSpeed calculation from samples.
        </li>
        <li>
          Update |this|.{{ComputePressureObserver/ComputePressureObserverUpdate/cpuUtilization}} with latest cpuUtilization calculation from samples.
        </li>
        <li>
          Update |this|.{{ComputePressureObserver/ComputePressureObserverUpdate/options}}
        </li>
        <li>
          Run |this|.{{ComputePressureObserver/[[Callback]]}} with |this|.{{ComputePressureObserver/ComputePressureObserverUpdate}} as argument.
        </li>
      </ol>
    </p>
  </section>
  <section>
    <h3>The <dfn>unobserve()</dfn> method</h3>
    <p>
      The {{ComputePressureObserver/unobserve()}} method, when invoked, MUST run the
      following step:
      <li>
        Remove {{ComputePressureObserver}} from the active observer [=list=]
      </li>
      <li>
        If |this:ComputePressureObserver| object was the last observer in the observer [=list=], sampling should stop.
      </li>
    </p>
  </section>
</section>

<section data-dfn-for="ComputePressureObserverUpdate">
  <h3>The <dfn>ComputePressureObserverUpdate</dfn> dictionary</h3>
  <pre class="idl">
    dictionary ComputePressureObserverUpdate {
      double cpuSpeed;
      double cpuUtilization;
      ComputePressureObserverOptions options;
    };
  </pre>
  <section>
    <h3>The <dfn>cpuSpeed</dfn> attribute</h3>
    <p>
      The {{ComputePressureObserverUpdate/cpuSpeed}} attribute represents the current [=CPU=] [=frequency=]
      as a {{double}} value between `0` and `1`.
    </p>
  </section>
  <section>
    <h3>The <dfn>cpuUtilization</dfn> attribute</h3>
    <p>
      The {{ComputePressureObserverUpdate/cpuUtilization}} attribute represents the current CPU <a> utilization</a>
      as a {{double}} value between `0` and `1`.
    </p>
  </section>
  <section>
    <h3>The <dfn>options</dfn> attribute</h3>
    <p>
      The {{ComputePressureObserverUpdate/options}} attribute represents the {{ComputePressureObserverOptions}}
      dictionary that {{ComputePressureObserver}} was constructed with.
    </p>
  </section>
</section>

<section data-dfn-for="ComputePressureObserverOptions">
  <h3>The <dfn>ComputePressureObserverOptions</dfn> dictionary</h3>
  <pre class="idl">
    dictionary ComputePressureObserverOptions {
      sequence&lt;double&gt; cpuUtilizationThresholds = [];
      sequence&lt;double&gt; cpuSpeedThresholds = [];
    };
  </pre>
  <section>
    <h3>The <dfn>cpuUtilizationThresholds</dfn> member</h3>
    <p>
      The {{ComputePressureObserverOptions/cpuUtilizationThresholds}} member represents the current {{CPU}} {{utilization}}
      thresholds, as a sequence of {{double}}s values between `0` and `1`.
    </p>
  </section>
  <section>
    <h3>The <dfn>cpuSpeedThresholds</dfn> member</h3>
    <p>
      The {{ComputePressureObserverOptions/cpuSpeedThresholds}} member represents the current [=CPU=] [=frequency=]
      thresholds, as a sequence of {{double}}s values between `0` and `1`.
    </p>
  </section>
</section>
<section>
  <h3>Reacting to telemetry changes</h3>
  <p>
    How a system queries or observes telemetry data is not defined by this specification and may vary, but when
    new telemetry data is available, run these steps:
  </p>
  <ol class="algorithm">
    <li>
      Let |document:Document| be the [=environment settings object/responsible document=] of the [=current settings object=].
    </li>
    <li>
      If |document| is not [=Document/fully active=], about these steps.
    </li>
</section>

<section>
  <h2>
    Security and privacy considerations
  </h2>
  <section>
    <h3>Minimizing information exposure</h3>
    <p>
      Exposing hardware related events related to {{CPU}} {{utilization}}
      <a href="https://w3ctag.github.io/design-principles/#device-ids">
      increases the risk of harming the user's privacy</a>.
    </p>
    <p>
      To minimize this risk, only the absolute minimal
      amount of information needed to to support the use-cases is exposed.
    </p>
    <p>
      The subsections below describe the processing model. At a high level, the
      information exposed is reduced by the following steps:
      <ol>
        <li>
          <b>Normalization</b> - Per-core information reported by the operating system is
          normalized to a number between 0.0 and 1.0. This removes variability across
          CPU models and operating systems.
        </li>
        <li>
          <b>Aggregation</b> - Normalized per-core information is aggregated into one
          overall number.
        </li>
        <li>
          <b>Quantization</b> (a.k.a. bucketing) - Each application (origin) must declare
          a small number of value ranges (buckets) where it wants to behave
          differently. The application doesn't receive the exact aggregation results,
          and instead only gets to learn the range (bucket) that each aggregated number
          falls within to.
        </li>
        <li>
          <b>Rate-limiting</b> - The user agent notifies the application of changes in
          the information it can learn (buckets that each aggregated number). Change
          notifications are rate-limited.
        </li>
      </ol>
      <section>
        <h4>Normalizing CPU utilization</h4>
        <p>
          The user agent will normalize CPU core utilization information reported by the
          operating system to a number between 0.0 and 1.0.
        </p>
        <p>
          0.0 maps to 0% utilization, meaning the CPU core was always idle during the
          observed time window. 1.0 maps to 100% utilization, meaning the CPU core
          was never idle during the observed time window.
        </p>
      </section>
      <section>
        <h4>Aggregating CPU utilization</h4>
        <p>
          CPU utilization is averaged over all enabled CPU cores.
        </p>
        <p>
          Under normal circumstances, all of a system's cores are enabled. However,
          mitigating some recent micro-architectural attacks on some devices may require
          completely disabling some CPU cores. For example, some Intel systems require
          disabling hyperthreading.
        </p>
        <p>
          We recommend that user agents aggregate CPU utilization over a time window of 1
          second. Smaller windows increase the risk of facilitating a side-channel attack.
          Larger windows reduce the application's ability to make timely decisions that
          avoid bad user experiences.
        </p>
      </section>
      <section>
        <h4>Normalizing CPU frequency</h4>
        <p>
          This API normalizes each CPU core's frequency to a number between `0.0` and `1.0`.
          The proposal intends to enable the decisions we set out to support, without
          exposing the [=CPU=] frequency steps.
        </p>
        <p>
           We recommend the following principles for normalizing a CPU core's [=frequencies=]
           <ul>
             <li>
              The minimum frequency is always reported as `0.0`.
             </li>
             <li>
              The base frequency is always reported as `0.5`.
             </li>
             <li>
              The maximum frequency is always reported as `1.0`.
             </li>
             <li>
              Speeds outside these values are clamped (to `0.0` or `1.0`).
             </li>
             <li>
              Speeds between these values are linearly interpolated.
             </li>
           </ul>
        </p>
      </section>
      <section>
        <h4>Aggregating CPU frequency</h4>
        <p class="issue">
          TODO: Aggregating is an average of the current speed across all cores. No
          aggregation over a time window. Proposal for aggregating frequencies across
          systems with heterogeneous CPU cores
        </p>
      </section>
      <section>
        <h4>Quantizing values (a.k.a. Bucketing)</h4>
        <p>
          Quantizing the aggregated CPU utilization and frequency reduces the amount of
          information exposed by the API.
        </p>
        <p>
          Having applications designate the quantization ranges (buckets) reduces the
          quantization resolution that user agents must support in order to enable the
          decisions used in a multitude of applications.
        </p>
        <p>
          Applications communicate their desired quantization scheme by passing in a list
          of thresholds. For example, the thresholds list `[0.5, 0.75, 0.9]` defines a
          4-bucket scheme, where the buckets cover the value ranges `0`-`0.5`, `0.5`-`0.75`,
          `0.75`-`0.9`, and `0.9`-`1.0`. We propose representing a bucket using the middle
          value in its range.
        </p>
        <p class="example">
          Suppose an application used the threshold list above, and the user
          agent measured a CPU utilization of `0.87`. This would fall under the `0.75`-`0.9`
          bucket, and would be reported as `0.825` (the average of `0.75` and `0.9`).
        </p>
        <p>
          We recommend that user agents allow at most 5 buckets (4 thresholds) for
          CPU utilization, and 2 buckets (1 threshold) for CPU speed.
        </p>
      </section>
      <section>
        <h4>Rate-limiting change notifications</h4>
        <p>
          We propose exposing the quantized CPU utilization and frequency via
          rate-limited change notifications. This aims to remove the ability to observe
          the precise time when a value transitions between two buckets.
        </p>
        <p>
          More precisely, once the compute pressure observer is installed, it will be
          called once with initial quantized values, and then be called when the quantized
          values change. The subsequent calls will be rate-limited. When the callback is
          called, the most recent quantized value is reported.
        </p>
        <p>
          The specification will recommend a rate limit of at most one call per second
          for the active window, and one call per 10 seconds for all other windows. We
          will also recommend that the call timings are jittered across origins.
        </p>
        <p>
          These measures benefit the user's privacy, by reducing the risk of
          identifying a device across multiple origins. The rate-limiting also benefits
          the user's security, by making it difficult to use this API for timing attacks.
          Last, rate-limiting change callbacks places an upper bound on the performance
          overhead of this API.
        </p>
      </section>
      <section>
        <h4>Third-party contexts</h4>
        <p>
          This API will only be available in frames served from the same origin as the
          top-level frame. This requirement is necessary for preserving the privacy
          benefits of the API's quantizing scheme.
        </p>
        <p>
          The same-origin requirement above implies that the API is only available in
          first-party contexts.
        </p>
      </section>
    </p>
  </section>
</section>
<section id="examples" class="informative">
  <h2>
    Examples
  </h2>
  <pre class="example js" title="Adjusting the number of video feeds based on CPU usage">
    const observer = new ComputePressureObserver(
      computePressureCallback,
      {
        cpuUtilizationThresholds: [0.75, 0.9, 0.5],
        cpuSpeedThresholds: [0.5],
      }
    );

    observer.observe();

    function computePressureCallback(update) {
      // The CPU base frequency is represented as 0.5.
      if (update.cpuSpeed >= 0.5) {
        // Dramatically cut down compute requirements to avoid overheating.
        limitVideoStreams(2);
        return;
      }

      if (update.cpuUtilization >= 0.9) {
        limitVideoStreams(2);
      } else if (update.cpuUtilization >= 0.75) {
        limitVideoStreams(4);
      } else if (update.cpuUtilization >= 0.5) {
        limitVideoStreams(8);
      } else {
        // The system is in great shape. Show all meeting participants.
        showAllVideoStreams();
      }
    }
  </pre>
</section>
<section id="conformance">
  <p>
    This is required for specifications that contain normative material.
  </p>
</section>

<section class="appendix informative" id="acknowledgments"> <h2>Acknowledgments</h2>
  <p>
    Many thanks for valuable feedback and advice from
    Chen Xing,
    Evan Shrubsole,
    Jesse Barnes,
    Kamila Hasanbega,
    Jan Gora,
    Joshua Bell,
    Matt Menke,
    Nicolás Peña Moreno,
    Opal Voravootivat,
    Paul Jensen,
    Peter Djeu,
    Reilly Grant,
    Ulan Degenbaev,
    Victor Miura,
    and
    Zhenyao Mo
  </p>
</section>
