
<!DOCTYPE html>
<meta charset="utf-8" />
<title>Compute Pressure API</title>
<script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove" defer></script>
<script class="remove">
  // All config options at https://respec.org/docs/
  const respecConfig = {
    shortName: "compute-pressure",
    group: "wicg",
    specStatus: "CG-DRAFT",
    xref: "web-platform",
    formerEditors: [
      {
        name: "Olivier Yiptong",
        company: "Google Inc.",
        companyURL: "https://google.com",
      }
    ],
    editors: [
      {
        name: "Victor Costan",
        company: "Google Inc.",
        companyURL: "https://google.com",
      },
      {
        name: "Kenneth Rohde Christiansen",
        company: "Intel Corporation",
        companyURL: "https://intel.com",
        w3cid: 57705,
      },
      {
        name: "Arnaud Mandy",
        company: "Intel Corporation",
        companyURL: "https://intel.com",
        w3cid: 126342,
      }
    ],
    testSuiteURI: "https://github.com/web-platform-tests/wpt/labels/compute-pressure",
  };
</script>
<section id="abstract">
  <p>
    The <cite>Compute Pressure API</cite> provides a way for websites to react to changes
    in the CPU consumption of the target device, such that websites can trade off CPU
    resources for an improved user experience.
  </p>
</section>
<section id="sotd"></section>
<section class="informative">
  <h2>Introduction</h2>
  <p>
    Modern applications often need to balance the trade offs and advantages of fully utilizing
    the system's processing resources, in order to provide a modern and delightful user experience.
  </p>
  <p>
    As an example, many applications can render video effects with varying degrees of sophistication.
    These applications aim to provide the best user experience, while avoiding driving the user's
    device into a high [=load=] regime.
  </p>
  <p>
    [=Utilization=] of [=processing units=] close to and often reaching 100% can lead to a bad
    user experience, as different tasks are fighting for the processing time.
    This can lead to slowless, which is especially noticeable with input delay.

    Further, a prolonged utilization close 100% can cause the [=processing units=] to heat up due to prolonged
    [=boosting=], which can lead to [=throttling=], resulting in an even worse user experience.
  </p>
  <p>
    As a result of thermal limits, many smartphones, tablets and laptops can become uncomfortably hot
    to the touch. The fans in laptops and desktops can become so loud that they disrupt conversations
    or the users’ ability to focus.
  </p>
  <p>
    In many cases, a device under high [=load=] appears to be unresponsive, as the operating
    system may fail to schedule the threads advancing the task that the user is waiting for. See also
    <a href="https://github.com/oyiptong/compute-pressure/#goals--motivating-use-cases">Compute Pressure:
    Use Cases</a>.
  </p>
</section>
<section>
  <h2>A Note on Feature Detection</h2>
  <p><i>This section is non-normative.</i></p>
  <p>
    Feature detection is an established web development best practice. Resources on the topic are plentiful on- and
    offline and the purpose of this section is not to discuss it further, but rather to put it in the context of
    detecting hardware-dependent features.
  </p>
  <p>
    Consider the below feature detection examples:
  </p>
  <aside class="example" title="Checking existence of ComputePressureObserver interface">
    <p>
      This simple example illustrates how to check whether the User Agent exposes the ComputePressureObserver interface
    </p>
    <pre class="js">
      if (typeof ComputePressureObserver == "function") {
        // use ComputePressureObserver interface
      }

      if ("ComputePressureObserver" in window) {
        // use ComputePressureObserver interface
      }

      if (window.ComputePressureObserver) {
        // use ComputePressureObserver interface
      }

      // etc.
    </pre>
  </aside>
  <p>
    All of these tell you something about the presence and possible characteristics of an API.
    They do not tell you anything, however, about whether that API is actually connected to a real [=platform collector=], whether the [=platform collector=] is collecting real telemetry readings,
    or whether the user is going to allow you to access it.
  </p>
</section>
<section>
  <h2>Concepts</h2>
  <p>
    This specification defines the following concepts:
  </p>
  <section>
    <h3><dfn>Processing Units</dfn></h3>
    <p>
      Computing devices consist of a multitude of different processing units such as the Central
      Processing Unit (<dfn>CPU</dfn>), Graphics Processing Unit (<dfn>GPU</dfn>) and many specialized
      processing units are becoming popular such as ones designed to accelerate specific tasks like
      machine learning or computer vision. This specification uses the term <dfn>XPU</dfn> to refer to
      <em>any</em> of these processing units.
    </p>
  </section>
  <section>
    <h3><dfn>Utilization</dfn></h3>
    <p>
      [=Processing Unit=] utilization refers to a device’s usage of the [=XPU=] processing
      resources, or the amount of work handled by an [=XPU=]. Not every task requires heavy [=XPU=]
      time as the task might depend on other resources, such as reading data from memory.
    </p>
    <p>
      [=XPU=] often contain multiple execution units/cores, so utilization refers to the
      <em>average percentage of the total working time of all execution units.</em>
    </p>
    <p>
      As an example, for a [=CPU=], the utilization is the fraction of time that each core has been
      executing code belonging to a thread, as opposed to being in an idle state.
    </p>
    <p>
      [=Processing Units=] are designed to run safely at 100% utilization. However, it means they have reached
      their limit and cannot take on additional work and maybe not even handle the current work at
      hand, resulting in perceptible slowness.
    </p>
  </section>
  <section>
    <h3><dfn>Load</dfn></h3>
    <p>
      For [=CPUs=], it is common to consider load in addition to [=utilization=]. Load is the number
      of processes (queue length) being executed or waiting to be by the CPU. When a system is
      heavily loaded, its [=CPU=] [=utilization=] is likely close to 100%, though a system with
      2 processes in the queue and one with 10 are not comparable. For this reason it is common
      to look at load average (average system load over a period of time) as a set of three
      numbers, which represent the load during the last one-, five-, and fifteen-minute periods.
    </p>
  </section>
  <section>
    <h3><dfn>Frequency</dfn></h3>
    <p>
      [=Processing units=] run at a certain frequency, also known as clock rate, expressed in
      cycles per second (e.g. gigahertz). The base frequency is a measure that the CPU manufacturer
      guarantees the [=processing unit=] can run at with reasonable cooling.
    </p>
    <p>
      To avoid [=processing units=] running at 100% utilization for long, some [=processing units=] can use <dfn>dynamic
      frequency scaling</dfn> to temporarily <dfn data-lt="boost|boosting">boost</dfn> the
      frequency of a certain execution unit and then assign the largest task to it, alleviating
      the poor user experience in many situations.
    </p>
    <p>
      The [=processing unit=] will try to increase the operating frequency in regular increments (steps)
      as required to meet demand. The increased frequency is limited by the [=processing unit=]'s power,
      current, and thermal limits, the number of execution units currently in use, and the maximum
      frequency of the active ones.
    </p>
    <p>
      [=Dynamic Frequency Scaling=] can also be used to
      <dfn data-lt="throttle|throttling">throttle</dfn> the execution,
      by slowing down the frequency to use less energy and conserve battery, especially in laptops.
    </p>
    <p>
      Throttling can also happen as a result of an [=processing unit=] reaching its thermal limits. This
      thermal throttling helps cool the [=processing unit=] down when it gets too hot by lowering the frequency.
    </p>
  </section>
  <section>
    <h3><dfn>Sampling Frequency</dfn> and <dfn>Reporting Frequency</dfn></h3>
    <p>
      The [=sampling frequency=] for a [=platform collector=] is defined as a frequency at which the user agent
      obtains telemetry readings from the underlying platform.
    </p>
    <p>
    The [=reporting frequency=] for a concrete {{ComputePressureObserver}} object is defined as a frequency
    at which {{ComputePressureUpdateCallback}} of this object will be invoked.
    </p>
    <p>
    A {{ComputePressureObserver}} object cannot access new readings at a higher rate than the user agent
      obtains them from the underlying platform, therefore the [=reporting frequency=] can never exceed the [=sampling frequency=].
    </p>
    <p>
      The [=reporting frequency=] can vary based on the difference in values between readings at [=sampling frequency=].
      If between two consecutive samplings the values of telemetry readings are falling into the same bucket, the values are considered
      to be unchanged and {{ComputePressureUpdateCallback}} of the object will not be invoked.
    </p>
  </section>
</section>

<section> <h2>Platform primitives</h2>
  <p>
    The term <dfn>platform collector</dfn> refers to platform interface, with which the [=user agent=] interacts to
    obtain the telemetry readings required by this specification.
  </p>
  <p>
    A [=platform collector=] can be defined by the underlying platform (e.g. in a native telemetry
    framework) or by the [=user agent=], if it has a direct access to hardware counters.
  </p>
  <p>
    From the implementation perspective [=platform collector=] can be treated as a software proxy for the
    corresponding hardware counters. It is possible to have multiple [=platform collector=] simultaneously
    interacting with the same underlying hardware if the underlying platform suppports it.
  </p>
  <p>
    In simple cases, a [=platform collector=] represents individual hardware counters, but if the provided
    counter readings are a product of data fusion performed in software, the [=platform collector=]
    represents the results of the data fusion process. This may happen in user space or in kernel space.
  </p>
  <p>
    As collecting telemetry data often means polling hardware counters, it is not a free operation and thus,
    it should not happen if there are no one observing the data. The term <dfn>active observers</dfn> refer
    to a [=user agent=] wide counter, representing how many instances of {{ComputePressureObserver}} that
    are active across the [=user agent=]. The [=active observers=] value is initially `0`.
  </p>
  <p>
    A [=platform collector=] samples data at a specific frequency. A [=user agent=] may modify this frequency
    (if possible) for privacy reasons, or ignore and fuse certain readings.
  </p>
  <p>
    When a sample is obtained from the [=platform collector=], the [=user agent=] MUST run the [[[#notify-observers]]]
    algorithm a per the [[[#processing-model]]]
  </p>
</section>

<section> <h2>Compute Pressure Observer</h2>
The Compute Pressure Observer API enables developers to understand the utilization characteristics of a CPU.

<section data-dfn-for="ComputePressureObserverCallback">
  <h3>The <a>ComputePressureUpdateCallback</a> callback</h3>
  <pre class="idl">
    callback ComputePressureUpdateCallback = undefined (
      ComputePressureEntry update,
      ComputePressureObserver observer
    );
  </pre>
  This callback will be invoked when [=CPU=] [=frequency=] and/or [=utilization=] crosses the user
  set thresholds.
</section>

<section  data-dfn-for="ComputePressureObserver"> <h2>The <a>ComputePressureObserver</a> object</h2>
  <p>
    The {{ComputePressureObserver}} can be used to observe changes in the [=CPU=] [=frequency=] and
      <a>utilization</a>, following user set thresholds.
  </p>
  <p>
    Providing a list of thresholds effectively separates the resource usage into buckets. For example,
    the thresholds list `[0.5, 0.75, 0.9]` defines a 4-bucket scheme, where the buckets cover the ranges
    `[0-0.5[`, `[0.5-0.75[`, `[0.75-0.9[`, and `[0.9-1.0]`.
  </p>
  <aside class="note">
    <p>
      The user of the API can request an arbitary number of thresholds, but the User Agent may choose to
      observe only a subset of those requested.
    </p>
    <p>
      It is recommended that user agents allow at most 5 buckets (4 thresholds) for CPU utilization, and
      2 buckets (1 threshold) for CPU speed.
    </p>
  </aside>
  <pre class="idl">
    [Exposed=Window]
    interface ComputePressureObserver {
      constructor(
        ComputePressureUpdateCallback callback,
        optional ComputePressureObserverOptions options = {}
      );
      undefined observe();
      undefined unobserve();
    };
  </pre>

  <p>The <dfn>ComputePressureObserver</dfn> interface represents a {{ComputePressureObserver}}.</p>

  <section  data-dfn-for="ComputePressureObserver">
    <h3>
      Internal slots
    </h3>
    <p>
      A constructed  {{ComputePressureObserver}} object has the following internal slots.
    </p>
    <table class="simple">
      <thead>
        <tr>
          <th>
            Internal slot
          </th>
          <th>
            Initial value
          </th>
          <th>
            Description
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>
            <dfn>[[\Callback]]</dfn>
          </td>
          <td>
            {{undefined}}
          </td>
          <td>
            An optional function of type {{ComputePressureUpdateCallback}}.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>[[\Activated]]</dfn>
          </td>
          <td>
            `false`
          </td>
          <td>
            A {{boolean}} whether the observer is actively observing or not.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>[[\CPUUtilizationThresholds]]</dfn>
          </td>
          <td>
            An empty [=list=].
          </td>
          <td>
            A [=list=] of {{double}}s between 0 and 1, representing
            the user requested {{CPU}} {{utilization}} thresholds.
          </td>
        </tr>
        <tr>
          <td>
            <dfn>[[\CPUSpeedThresholds]]</dfn>
          </td>
          <td>
            An empty [=list=].
          </td>
          <td>
            A [=list=] of {{double}}s between 0 and 1, representing
            the user requested [=CPU=] [=frequency=] thresholds.
          </td>
        </tr>
      </tbody>
    </table>
  </section>
  <section>
    <h3>The <dfn>constructor()</dfn> method</h3>
    <p>
      The {{ComputePressureObserver/constructor()}} method, when invoked, MUST run the
      following step, given the arguments |callback:ComputePressureUpdateCallback| and
      |options:ComputePressureObserverOptions|:
      <ol class="algorithm">
        <li>
          Let |this:ComputePressureObserver| be a new the {{ComputePressureObserver}} object.
        </li>
        <li>
          Set |this|.{{ComputePressureObserver/[[Callback]]}} to |callback|.
        </li>
        <li>
          If |options|.|cpuUtilizationThresholds:list| exists, set |this|.{{ComputePressureObserver/[[CPUUtilizationThresholds]]}}
          be a [=list=] equal to that.
        </li>
        <li>
          If any value in |this|.{{ComputePressureObserver/[[CPUUtilizationThresholds]]}} is less than 0.0 or greater than 1.0,
          throw a {{RangeError}} exception.
        </li>
        <li>
          Sort |this|.{{ComputePressureObserver/[[CPUUtilizationThresholds]]}} in ascending order.
        </li>
        <li>
          If |options|.|cpuSpeedThresholds:list| exists, set |this|.{{ComputePressureObserver/[[CPUSpeedThresholds]]}}
          be a [=list=] equal to that.
        </li>
        <li>
          If any value in |this|.{{ComputePressureObserver/[[CPUSpeedThresholds]]}} is less than 0.0 or greater than 1.0,
          throw a {{RangeError}} exception.
        </li>
        <li>
          Sort |this|.{{ComputePressureObserver/[[CPUSpeedThresholds]]}} in ascending order.
        </li>
        <li>
          Return |this|.
        </li>
    </p>
  </section>
  <section>
    <h3>The <dfn>observe()</dfn> method</h3>
    <p>
      The {{ComputePressureObserver/observe()}} method, when invoked, MUST run the
      following step:
      <ol class="algorithm">
        <li>
          If [=active observers=] is equal to `0`, activate the underlying [=platform collector=].
        </li>
        <li>
          Increment the [=active observers=] counter.
        </li>
        <li>
          Set |this|.{{ComputePressureObserver/[[Activated]]}} to `true`.
        </li>
      </ol>
    </p>
  </section>
  <section>
    <h3>The <dfn>unobserve()</dfn> method</h3>
    <p>
      The {{ComputePressureObserver/unobserve()}} method, when invoked, MUST run the
      following step:
      <ol class="algorithm">
        <li>
          Decrement the [=active observers=] counter.
        </li>
        <li>
          If [=active observers=] is equal to `0`, deactivate the underlying [=platform collector=].
        </li>
        <li>
          Set |this|.{{ComputePressureObserver/[[Activated]]}} to `false`.
        </li>
      </ol>
    </p>
  </section>
</section>

<section data-dfn-for="ComputePressureEntry">
  <h3>The <dfn>ComputePressureEntry</dfn> dictionary</h3>
  <pre class="idl">
    dictionary ComputePressureEntry {
      double cpuSpeed;
      double cpuUtilization;
      ComputePressureObserverOptions options;
    };
  </pre>
  <section>
    <h3>The <dfn>cpuSpeed</dfn> attribute</h3>
    <p>
      The {{ComputePressureEntry/cpuSpeed}} attribute represents the current [=CPU=] [=frequency=]
      as a {{double}} value between `0` and `1`.
    </p>
  </section>
  <section>
    <h3>The <dfn>cpuUtilization</dfn> attribute</h3>
    <p>
      The {{ComputePressureEntry/cpuUtilization}} attribute represents the current CPU <a> utilization</a>
      as a {{double}} value between `0` and `1`.
    </p>
  </section>
  <section>
    <h3>The <dfn>options</dfn> attribute</h3>
    <p>
      The {{ComputePressureEntry/options}} attribute represents the {{ComputePressureObserverOptions}}
      dictionary that {{ComputePressureObserver}} was constructed with.
    </p>
  </section>
</section>

<section data-dfn-for="ComputePressureObserverOptions">
  <h3>The <dfn>ComputePressureObserverOptions</dfn> dictionary</h3>
  <pre class="idl">
    dictionary ComputePressureObserverOptions {
      sequence&lt;double&gt; cpuUtilizationThresholds = [];
      sequence&lt;double&gt; cpuSpeedThresholds = [];
    };
  </pre>
  <section>
    <h3>The <dfn>cpuUtilizationThresholds</dfn> member</h3>
    <p>
      The {{ComputePressureObserverOptions/cpuUtilizationThresholds}} member represents the current {{CPU}} {{utilization}}
      thresholds, as a sequence of {{double}}s values between `0` and `1`.
    </p>
  </section>
  <section>
    <h3>The <dfn>cpuSpeedThresholds</dfn> member</h3>
    <p>
      The {{ComputePressureObserverOptions/cpuSpeedThresholds}} member represents the current [=CPU=] [=frequency=]
      thresholds, as a sequence of {{double}}s values between `0` and `1`.
    </p>
  </section>
</section>
<section id="processing-model">
  <h3>Processing Model</h3>
  <p>
    This section outlines the steps the user agent must take when implementing the Compute Pressure Observer API.
  </p>
  <section id="handle-cpu-utilization">
    <h3>Normalize and aggregate CPU utilization</h3>
    <aside class="note">
      <p>
      CPU utilization can have different meaning. In the context of Compute Pressure API, CPU utilization is the time when
      the CPU core is not in idle state. Any other state is considered to be an utilization state. Utilization states can be
      when the CPU core is busy or is stalled or waiting for memory I/O for example.
      </p>
      <p>
      Depending on the platform, CPU utilization can be directly read at time t, or can be derived from a calculation of different
      utilization state during a pre-defined time interval.
      </p>
    </aside>
    <ol class="algorithm">
      <li>
        Let |core count| equal to the numbers of CPU cores as part of |platform reading|.
      </li>
      <li>
        Let |aggregated utilization| be `0.0`.
      </li>
        [=list/For each=] CPU core,
        <ol>
          <li>
            Calculate or read CPU |utilization|.
          </li>
          <li>
            Normalize |utilization| so that its value is in between 0.0 and 1.0.
          </li>
          <li>
            Set |aggregated utilization| to |aggregated utilization| + |utilization|.
          </li>
        </ol>
      <li>
        Set |aggregated utilization| to |aggregated utilization| / |core count|.
      </li>
    </ol>
  </section>
  <section id="handle-cpu-frequency">
    <h3>Normalize and aggregate CPU frequency</h3>
    <aside class="note">
      <p>
        CPU cores may support a variety of complex [=dynamic frequency scaling=] technologies to raise the
        clock frequency beyond the base frequency (max frequency without [=boosting=]).
      </p>
      <p>
        The [=boosting=] max frequency can depend on the type of core in heterogeneous systems, but even
        the same cores can have different max frequency. In modern Intel CPUs, one or two P-cores (performance
        cores) are considered <em>favored cores</em> with even higher max frequency.
      </p>
      <p>
        Beyond this, Intel CPUs might support <em>Thermal Velocity Boost</em> (TVB), which allows an even higher
        frequency, going beyond the max frequency if the CPU’s within temperature limits and turbo power budget is
        available.
      </p>
      <p>
        Overclocked CPUs can similarly go beyond the [=boosting=] max frequency.
      </p>
      <p>
        Frequencies beyond [=boosting=] max frequency are ignored by this specification and frequencies are
        clamped to the [=boosting=] max frequency.
      </p>
      <p>
        More information about Intel based boosting technologies <a
        href="https://www.intel.com/content/www/us/en/gaming/resources/how-intel-technologies-boost-cpu-performance.html">
        here</a>.
      </p>
    </aside>
    This algorithm, when invoked, MUST run the following step, given the argument |platform reading|:
    <ol class="algorithm">
      <li>
        Let |core count| equal to the numbers of CPU cores as part of |platform reading|.
      </li>
      <li>
        Let |aggregated frequency| be `0.0`.
      </li>
      <li>
        [=list/For each=] CPU core reading |core info| as part of |platform reading|,
        <ol>
          <li>
            Let |frequency| be the current frequency associated with |core info|.
          </li>
          <li>
            Let |min|, |base| and |turbo| be the CPU core's minimum, base and turbo [=boosting=] max frequencies.
          </li>
          <li>
            If |frequency| < |base|,
            <ul>
              <li>
                Set |frequency| to (|frequency| - |min|) / ((|base| - |min|) * 2).
              </li>
            </ul>
          </li>
          <li>
            If |frequency| &#8805 |base|,
            <ul>
              <li>
                Set |frequency| to (|frequency| - |base|) / ((|turbo|  - |base|) * 2) + 0.5.
              </li>
            </ul>
          </li>
          <li>
            Set |frequency| to <a href="https://tc39.es/ecma262/#eqn-max">max</a>(0, |frequency|).
          </li>
          <li>
            Set |frequency| to <a href="https://tc39.es/ecma262/#eqn-min">min</a>(1, |frequency|).
          </li>
          <li>
            Set |aggregated frequency| to |aggregated frequency| + |frequency|.
          </li>
        </ol>
      <li>
        Set |aggregated frequency| to |aggregated frequency| / |core count|.
      </li>
      <li>
        Return |aggregated frequency|.
      </li>
    </ol>
  </section>
  <section id="create-entry">
    <h3>Create and populate a ComputePressureEntry</h3>
    <ol class="algorithm">
      <li>
        Let |readings| be the latest reading of the [=platform collector=].
      </li>
      <li>
        Let |entry:ComputePressureEntry| be a new {{ComputePressureEntry}} instance.
      </li>
      <li>
        Let |entry|.|cpuSpeed:double| be the result of invoking [[[#handle-cpu-frequency]]] with
        |readings|.
      </li>
      <li>
        Return |entry|.
      </li>
    </ol>
  </section>
  <section id="notify-observers">
    <h3>Notify Compute Pressure Observers</h3>
    <ol class="algorithm">
      <li>
        Let |document:Document| be the [=environment settings object/responsible document=] of the [=current settings object=].
      </li>
      <li>
        If |document| is not [=Document/fully active=], about these steps.
      </li>
      <li>
        [=list/For each=] {{ComputePressureObserver}} instance |observer:ComputePressureObserver|,
        <ol>
          <li>
            If |observer|.{{ComputePressureObserver/[[Activated]]}} is `false`, then [=iteration/continue=].
          </li>
          <li>
            Let |entry| be the result of running [[[#create-entry]]].
          </li>
          <li>
            Let |entries| be the [=list=] « |entry| ».
          </li>
          <li>
            Invoke |observer|.{{ComputePressureObserver/[[Callback]]}} with |entries| and |observer|.
          </li>
        </ol>
      </li>
    </ol>
  </section>
</section>

<section>
  <h2>
    Security and privacy considerations
  </h2>
  <section>
    <h3>Minimizing information exposure</h3>
    <p>
      Exposing hardware related events related to [=CPU=] [=utilization=]
      <a href="https://w3ctag.github.io/design-principles/#device-ids">
      increases the risk of harming the user's privacy</a>.
    </p>
    <p>
      To minimize this risk, only the absolute minimal
      amount of information needed to to support the use-cases is exposed.
    </p>
    <p>
      The subsections below describe the processing model. At a high level, the
      information exposed is reduced by the following steps:
      <ol>
        <li>
          <b>Normalization</b> - Per-core information reported by the operating system is
          normalized to a number between 0.0 and 1.0. This removes variability across
          CPU models and operating systems.
        </li>
        <li>
          <b>Aggregation</b> - Normalized per-core information is aggregated into one
          overall number.
        </li>
        <li>
          <b>Quantization</b> (a.k.a. bucketing) - Each application (origin) must declare
          a small number of value ranges (buckets) where it wants to behave
          differently. The application doesn't receive the exact aggregation results,
          and instead only gets to learn the range (bucket) that each aggregated number
          falls within to.
        </li>
        <li>
          <b>Rate-limiting</b> - The user agent notifies the application of changes in
          the information it can learn (buckets that each aggregated number). Change
          notifications are rate-limited.
        </li>
      </ol>
      <section>
        <h4>Normalizing CPU utilization</h4>
        <p>
          The user agent will normalize CPU core utilization information reported by the
          operating system to a number between 0.0 and 1.0.
        </p>
        <p>
          0.0 maps to 0% utilization, meaning the CPU core was always idle during the
          observed time window. 1.0 maps to 100% utilization, meaning the CPU core
          was never idle during the observed time window.
        </p>
      </section>
      <section>
        <h4>Aggregating CPU utilization</h4>
        <p>
          CPU utilization is averaged over all enabled CPU cores.
        </p>
        <p>
          Under normal circumstances, all of a system's cores are enabled. However,
          mitigating some recent micro-architectural attacks on some devices may require
          completely disabling some CPU cores. For example, some Intel systems require
          disabling hyperthreading.
        </p>
        <p>
          We recommend that user agents aggregate CPU utilization over a time window of 1
          second. Smaller windows increase the risk of facilitating a side-channel attack.
          Larger windows reduce the application's ability to make timely decisions that
          avoid bad user experiences.
        </p>
      </section>
      <section>
        <h4>Normalizing CPU frequency</h4>
        <p>
          This API normalizes each CPU core's frequency to a number between `0.0` and `1.0`.
          The proposal intends to enable the decisions we set out to support, without
          exposing the [=CPU=] frequency steps.
        </p>
        <p>
           We recommend the following principles for normalizing a CPU core's [=frequencies=]
           <ul>
             <li>
              The minimum frequency is always reported as `0.0`.
             </li>
             <li>
              The base frequency is always reported as `0.5`.
             </li>
             <li>
              The maximum frequency is always reported as `1.0`.
             </li>
             <li>
              Speeds outside these values are clamped (to `0.0` or `1.0`).
             </li>
             <li>
              Speeds between these values are linearly interpolated.
             </li>
           </ul>
        </p>
      </section>
      <section>
        <h4>Aggregating CPU frequency</h4>
        <p class="issue">
          TODO: Aggregating is an average of the current speed across all cores. No
          aggregation over a time window. Proposal for aggregating frequencies across
          systems with heterogeneous CPU cores
        </p>
      </section>
      <section>
        <h4>Quantizing values (a.k.a. Bucketing)</h4>
        <p>
          Quantizing the aggregated CPU utilization and frequency reduces the amount of
          information exposed by the API.
        </p>
        <p>
          Having applications designate the quantization ranges (buckets) reduces the
          quantization resolution that user agents must support in order to enable the
          decisions used in a multitude of applications.
        </p>
        <p>
          Applications communicate their desired quantization scheme by passing in a list
          of thresholds. For example, the thresholds list `[0.5, 0.75, 0.9]` defines a
          4-bucket scheme, where the buckets cover the value ranges `0`-`0.5`, `0.5`-`0.75`,
          `0.75`-`0.9`, and `0.9`-`1.0`. We propose representing a bucket using the middle
          value in its range.
        </p>
        <p class="example">
          Suppose an application used the threshold list above, and the user
          agent measured a CPU utilization of `0.87`. This would fall under the `0.75`-`0.9`
          bucket, and would be reported as `0.825` (the average of `0.75` and `0.9`).
        </p>
        <p>
          We recommend that user agents allow at most 5 buckets (4 thresholds) for
          CPU utilization, and 2 buckets (1 threshold) for CPU speed.
        </p>
      </section>
      <section>
        <h4>Rate-limiting change notifications</h4>
        <p>
          We propose exposing the quantized CPU utilization and frequency via
          rate-limited change notifications. This aims to remove the ability to observe
          the precise time when a value transitions between two buckets.
        </p>
        <p>
          More precisely, once the compute pressure observer is installed, it will be
          called once with initial quantized values, and then be called when the quantized
          values change. The subsequent calls will be rate-limited. When the callback is
          called, the most recent quantized value is reported.
        </p>
        <p>
          The specification will recommend a rate limit of at most one call per second
          for the active window, and one call per 10 seconds for all other windows. We
          will also recommend that the call timings are jittered across origins.
        </p>
        <p>
          These measures benefit the user's privacy, by reducing the risk of
          identifying a device across multiple origins. The rate-limiting also benefits
          the user's security, by making it difficult to use this API for timing attacks.
          Last, rate-limiting change callbacks places an upper bound on the performance
          overhead of this API.
        </p>
      </section>
      <section>
        <h4>Third-party contexts</h4>
        <p>
          This API will only be available in frames served from the same origin as the
          top-level frame. This requirement is necessary for preserving the privacy
          benefits of the API's quantizing scheme.
        </p>
        <p>
          The same-origin requirement above implies that the API is only available in
          first-party contexts.
        </p>
      </section>
    </p>
  </section>
</section>
<section id="examples" class="informative">
  <h2>
    Examples
  </h2>
  <pre class="example js" title="Adjusting the number of video feeds based on CPU usage">
    const observer = new ComputePressureObserver(
      computePressureCallback,
      {
        cpuUtilizationThresholds: [0.75, 0.9, 0.5],
        cpuSpeedThresholds: [0.5],
      }
    );

    observer.observe();

    function computePressureCallback(update) {
      // The CPU base frequency is represented as 0.5.
      if (update.cpuSpeed >= 0.5) {
        // Dramatically cut down compute requirements to avoid overheating.
        limitVideoStreams(2);
        return;
      }

      if (update.cpuUtilization >= 0.9) {
        limitVideoStreams(2);
      } else if (update.cpuUtilization >= 0.75) {
        limitVideoStreams(4);
      } else if (update.cpuUtilization >= 0.5) {
        limitVideoStreams(8);
      } else {
        // The system is in great shape. Show all meeting participants.
        showAllVideoStreams();
      }
    }
  </pre>
</section>
<section id="conformance">
  <p>
    This is required for specifications that contain normative material.
  </p>
</section>

<section class="appendix informative" id="acknowledgments"> <h2>Acknowledgments</h2>
  <p>
    Many thanks for valuable feedback and advice from
    Arnaud Mandy,
    Chen Xing,
    Evan Shrubsole,
    Jesse Barnes,
    Kamila Hasanbega,
    Jan Gora,
    Joshua Bell,
    Matt Menke,
    Nicolás Peña Moreno,
    Opal Voravootivat,
    Paul Jensen,
    Peter Djeu,
    Reilly Grant,
    Ulan Degenbaev,
    Victor Miura,
    and
    Zhenyao Mo
  </p>
</section>

<section id="idl-index" class="appendix">
  <!-- All the Web IDL will magically appear here -->
</section>
